## M1.1

### 总结回顾检查点
1. 爬虫是什么？
2. HTTP 协议的基本原理规范你大概了解了吗？
3. 你能想到几种不同的爬取这道题所需信息的方式？它们分别有什么特点？

大致回答一下
- 1.访问该网页的url，用http请求获取信息。再处理获取到的信息。
- 2.HTTP 协议是 Web 浏览器和服务器之间通信的基础，它基于请求/响应模型工作，客户端向服务器发送请求，服务器返回响应。
**url**  用于标识网页或资源的位置
**请求方法** GET(请求资源) POST(提交数据) 还有PUT DELETE等等。
**响应状态码** 标识服务器处理请求的结果:200 成功 404：请求的资源不存在。400：请求有误，参数不合法 500：服务器内部错误。
**请求和响应的内容** 请求头，响应头，请求体和响应体
- 3.我只会调用cf官方给的api接口，这种方式比较便捷，响应比较快，返回的JSON数据比较稳定。缺点是cf官方明确指出了 API may be requested at most 1 time per two seconds.

### 进阶思考题
1. 如果允许传入多个 handle，如 ./cf_crawler jiangly tourist，你会如何实现以及如何设计输出的数据结构和返回码呢？

- 1.我传参的时候用split方法把它分割成String数组了，调用for(handle : handles)这样的for循环即可。
- 2.关于返回码，如果有错误，会返回1。但是我的代码用了while(true)去处理多组输入，直到单行输入exit才会允许结束代码正常结束返回0。

## M1.2


### 总结回顾检查点
1. 什么场景适合爬取 HTML？什么场景适合爬取 API？它们分别有什么优劣？
- 1.第一个问题暂时不会。
- 2.第二个问题的话，网站给定公开的api之后会好一点，或者我想得到比较结构化的数据(比如json，xml)或者我对稳定性有要求。
这种方式比较便捷，效率比较高，返回的JSON数据比较稳定吧。缺点是可能会有请求频率限制，比如cf官方明确指出"API may be requested at most 1 time per two seconds."

2. 有哪些常见爬虫的异常情况需要考虑？
- 连接超时，我设置了超时实现5000ms
- 读取超时，我也设置了超时实现5000ms
- 状态码异常，正常来说GET该是200的 201是请求被成功处理并且在服务端创建了一个或多个新的资源 202：服务端已经接收到了请求，但是还未处理。204：服务端已经成功处理了请求，但是没有返回任何内容。
- api调用异常，比如参数不正确啥的


## 关于配置环境的问题
- 1.给maven添加依赖。我新创建的简陋项目根本没有maven，哭了。之前接触过带maven的项目是cs61b里老师给提供好的，我只需要导入就行了。
然后嘞，添加框架支持 + 选择maven后，系统就会自动生成一个pom.xml，就可以进去加上我需要的官方给定的json依赖啦。
- 2.如果没有实现控制台的输入的话，需要自己创建java临时文件才能跑。需要填一下名称，主要类，临时文件路径，程序实参(比如在我的这个代码里面是要填handle)，剩下几个可以默认。如果已经实现了控制台的输入可以忽略第二条。


## 关于代码构造中的问题
- 1.api的调用
这一点cf明确的给出来了参考文档，还是挺好的嘿嘿嘿。

- 2.用HttpURLConnection接收Url，并设置连接的查询方式，连接超时时限和读取超时时限，
并处理连接的响应的状态码

- 3.用输入流读取Connection里的信息并存到StringBuilder里
- 4.StringBuilder转JSONObject(转的时候以HashMap自动维护了，就直接可以以key去查询value)
对JSONObject操作。
注意各种异常问题，这里改了半天。

- 5.主函数里新加scanner，用控制台输入handle，调用我们之前已经做好的方法后，得到json对象后，
查询并进行对应的输出。

前四步的处理是我之前很难想象到的新鲜东西(除了输入流)，查了很多东西之后是真的学到了嘿嘿嘿。
这我就得狠狠吐槽java的爬虫教学太少了，全靠自己查资料。